{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using m250\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from configparser import ConfigParser\n",
    "\n",
    "cfg = ConfigParser()\n",
    "cfg.read('../config.ini')\n",
    "imgs_dir = cfg.get('dirs', 'img_tiles')\n",
    "fetex_dir = cfg.get('dirs','fetex')\n",
    "accidents_dir = cfg.get('dirs', 'accidentes')\n",
    "metrics_dir = cfg.get('dirs', 'road_metrics')\n",
    "grid_id = cfg.get('grid', 'default')\n",
    "print(f'using {grid_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Read the labels file created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'../support_data/{grid_id}/train.csv')\n",
    "test = pd.read_csv(f'../support_data/{grid_id}/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Using that split we create both image and metric splits\n",
    "\n",
    "- Images split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Csv data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_columns(data):\n",
    "    data.columns = map(str.lower, data.columns)\n",
    "    data.columns = map(str.strip, data.columns)\n",
    "    if 'geometry' in data.columns:\n",
    "        data.drop('geometry', axis=1, inplace=True)\n",
    "    if 'processed' in data.columns:\n",
    "        data.drop('processed', axis=1, inplace=True)\n",
    "    if 'sample' in data.columns:\n",
    "        data.drop('sample', axis=1, inplace=True)\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "def join_dataframes(*multiple_df):\n",
    "    output = []\n",
    "    for df in multiple_df:\n",
    "        if len(output):\n",
    "            output = df.join(output)\n",
    "        else:\n",
    "            output = df\n",
    "    print(output.dropna().shape)\n",
    "    return output.dropna()       \n",
    "\n",
    "\n",
    "# Load Accidents\n",
    "accidents = pd.read_csv(f'{accidents_dir}/{grid_id}_c.csv')\n",
    "accidents = clean_up_columns(accidents) \n",
    "accidents.set_index('id', inplace=True)\n",
    "\n",
    "# Load Fetex\n",
    "fetex = pd.read_csv(f'{fetex_dir}/r_fetex_{grid_id}.txt')\n",
    "fetex = clean_up_columns(fetex)\n",
    "fetex.set_index('id', inplace=True)\n",
    "\n",
    "# Load metrics data\n",
    "metrics = pd.read_csv(f'{metrics_dir}/250.csv', delimiter=';')\n",
    "metrics = clean_up_columns(metrics)\n",
    "metrics.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1019, 51)\n",
      "(446, 51)\n"
     ]
    }
   ],
   "source": [
    "# Load train/test split\n",
    "train = pd.read_csv(f'../support_data/{grid_id}/train.csv', index_col='id')\n",
    "test = pd.read_csv(f'../support_data/{grid_id}/test.csv', index_col='id')\n",
    "\n",
    "train = join_dataframes(train, fetex, metrics)\n",
    "test = join_dataframes(test, fetex, metrics)\n",
    "\n",
    "data = {'train':train, 'test':test}\n",
    "\n",
    "x_train, y_train = train.drop('label', axis=1), train.label\n",
    "x_test, y_test = test.drop('label', axis=1), test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0\n",
      "train 1\n",
      "train 3\n",
      "train 2\n",
      "test 0\n",
      "test 3\n",
      "test 2\n",
      "test 1\n"
     ]
    }
   ],
   "source": [
    "# Images split\n",
    "for split, df in data.items():\n",
    "    labels = df.label.unique().tolist()\n",
    "    split_imgs_path = f'{imgs_dir}/{grid_id}/{split}'\n",
    "    \n",
    "    if not os.path.exists(split_imgs_path):\n",
    "        os.mkdir(split_imgs_path)\n",
    "        \n",
    "    for label in labels:\n",
    "        label = int(label)\n",
    "        ids = df[df['label'] == label].index.tolist()\n",
    "        label_dir = f'{split_imgs_path}/{label}'\n",
    "        if not os.path.exists(label_dir):\n",
    "            os.mkdir(label_dir)\n",
    "        print(split, label)\n",
    "        for idx in ids:\n",
    "            if os.path.exists(f'{imgs_dir}/{grid_id}/jpg/{idx}.jpg'):\n",
    "                #print(os.path.exists(f'{imgs_dir}/{grid_id}/jpg/{idx}.jpg'))\n",
    "                os.rename(f'{imgs_dir}/{grid_id}/jpg/{idx}.jpg',\n",
    "                          f'{imgs_dir}/{grid_id}/{split}/{label}/{idx}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, features = x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Una vez creado el split de imágenes podemos usar keras para hacer la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple inputs\n",
    "import numpy as np\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.applications import InceptionV3, VGG16\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup training parameters\n",
    "\"\"\"\n",
    "batch_size = 2\n",
    "num_classes = 4\n",
    "inceptionv3_last_block_layer_number = 249\n",
    "vgg16_last_block_layer_number = 25\n",
    "img_width, img_height = 420, 420\n",
    "num_epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1019 images belonging to 4 classes.\n",
      "Found 446 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create image generators\n",
    "\"\"\"\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    f'{imgs_dir}/{grid_id}/train/',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    f'{imgs_dir}/{grid_id}/test/',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "def my_generator(image_gen, data):\n",
    "    while True:\n",
    "        i = image_gen.batch_index\n",
    "        batch = image_gen.batch_size\n",
    "        row = data[i*batch:(i+1)*batch]\n",
    "        images, labels = image_gen.next()\n",
    "        \n",
    "        yield [images, row], labels\n",
    "    \n",
    "            \n",
    "csv_train_generator = my_generator(train_generator, x_train)\n",
    "csv_test_generator = my_generator(test_generator, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1019"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONLY Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "509/509 [==============================] - 169s 333ms/step - loss: 2.2158 - acc: 0.3900 - val_loss: 1.3690 - val_acc: 0.4552\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.45516, saving model to models/only_images_vgg16.h5\n",
      "Epoch 2/15\n",
      "509/509 [==============================] - 180s 353ms/step - loss: 1.2448 - acc: 0.4862 - val_loss: 1.2037 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.45516 to 0.50673, saving model to models/only_images_vgg16.h5\n",
      "Epoch 3/15\n",
      "509/509 [==============================] - 179s 352ms/step - loss: 1.0119 - acc: 0.5737 - val_loss: 1.2178 - val_acc: 0.5269\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.50673 to 0.52691, saving model to models/only_images_vgg16.h5\n",
      "Epoch 4/15\n",
      "509/509 [==============================] - 179s 352ms/step - loss: 0.9433 - acc: 0.5914 - val_loss: 1.1444 - val_acc: 0.5090\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/15\n",
      "509/509 [==============================] - 179s 352ms/step - loss: 0.8616 - acc: 0.6228 - val_loss: 1.1630 - val_acc: 0.5112\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/15\n",
      "509/509 [==============================] - 178s 350ms/step - loss: 0.8062 - acc: 0.6572 - val_loss: 1.2753 - val_acc: 0.4753\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/15\n",
      "509/509 [==============================] - 179s 352ms/step - loss: 0.7624 - acc: 0.6896 - val_loss: 1.2997 - val_acc: 0.4709\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/15\n",
      "509/509 [==============================] - 178s 350ms/step - loss: 0.6975 - acc: 0.7210 - val_loss: 1.2207 - val_acc: 0.4978\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create simple classifier and use after network\n",
    "\"\"\"\n",
    "np.random.seed(7)\n",
    "main_input = Input(shape=(img_width, img_height, 3))\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=main_input)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=predictions)\n",
    "top_weights_path = 'models/only_images_vgg16.h5'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "opt = SGD(lr=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback_list = [\n",
    "    ModelCheckpoint(top_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "    EarlyStopping(monitor='val_acc', patience=5, verbose=0),\n",
    "    TensorBoard(log_dir=f'logs/only_images_vgg16')\n",
    "]\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch= train_generator.n // batch_size,\n",
    "    epochs=15,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps= test_generator.n // batch_size,\n",
    "    callbacks=callback_list)\n",
    "\n",
    "model.load_weights(top_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "509/509 [==============================] - 168s 329ms/step - loss: 0.9008 - acc: 0.6031 - val_loss: 1.2178 - val_acc: 0.5269\n",
      "\n",
      "Epoch 00001: val_acc did not improve\n",
      "Epoch 2/15\n",
      "509/509 [==============================] - 176s 345ms/step - loss: 0.9006 - acc: 0.6041 - val_loss: 1.2178 - val_acc: 0.5269\n",
      "\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 3/15\n",
      "509/509 [==============================] - 176s 347ms/step - loss: 0.9025 - acc: 0.6041 - val_loss: 1.2178 - val_acc: 0.5269\n",
      "\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 4/15\n",
      "509/509 [==============================] - 177s 348ms/step - loss: 0.9008 - acc: 0.6012 - val_loss: 1.2178 - val_acc: 0.5269\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/15\n",
      "509/509 [==============================] - 179s 352ms/step - loss: 0.9006 - acc: 0.6061 - val_loss: 1.2178 - val_acc: 0.5269\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/15\n",
      "509/509 [==============================] - 176s 346ms/step - loss: 0.8981 - acc: 0.6041 - val_loss: 1.2178 - val_acc: 0.5269\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "After training for a few epochs, freeze the bottom layers, and train only on top.\n",
    "\"\"\"\n",
    "for layer in model.layers[:vgg16_last_block_layer_number]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[vgg16_last_block_layer_number:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "opt = SGD(lr=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "final_weights_path = 'models/only_images_vgg16.h5'\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // batch_size,\n",
    "    epochs=15,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.n // batch_size,\n",
    "    callbacks=callback_list)\n",
    "\n",
    "model.save(final_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "y_predict = model.predict_generator(test_generator, workers=-1)\n",
    "y_predict_classes = y_predict.argmax(axis=-1)\n",
    "\n",
    "cm = confusion_matrix(test_generator.classes, y_predict_classes)\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.title('ONLY IMAGES CM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Images and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "509/509 [==============================] - 185s 363ms/step - loss: 11.1623 - acc: 0.3075 - val_loss: 11.4646 - val_acc: 0.2870\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.28700, saving model to models/multi_vgg16_top_model.h5\n",
      "Epoch 2/15\n",
      "509/509 [==============================] - 194s 382ms/step - loss: 10.9565 - acc: 0.3202 - val_loss: 11.6022 - val_acc: 0.2803\n",
      "\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 3/15\n",
      "509/509 [==============================] - 195s 383ms/step - loss: 10.9565 - acc: 0.3202 - val_loss: 11.3901 - val_acc: 0.2915\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.28700 to 0.29148, saving model to models/multi_vgg16_top_model.h5\n",
      "Epoch 4/15\n",
      "509/509 [==============================] - 197s 386ms/step - loss: 11.0515 - acc: 0.3143 - val_loss: 11.6467 - val_acc: 0.2758\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/15\n",
      "509/509 [==============================] - 198s 389ms/step - loss: 11.0832 - acc: 0.3124 - val_loss: 11.6095 - val_acc: 0.2780\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/15\n",
      "509/509 [==============================] - 197s 388ms/step - loss: 10.7507 - acc: 0.3330 - val_loss: 11.2810 - val_acc: 0.2982\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.29148 to 0.29821, saving model to models/multi_vgg16_top_model.h5\n",
      "Epoch 7/15\n",
      "509/509 [==============================] - 196s 385ms/step - loss: 11.1940 - acc: 0.3055 - val_loss: 11.8258 - val_acc: 0.2646\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/15\n",
      "509/509 [==============================] - 197s 387ms/step - loss: 11.0040 - acc: 0.3173 - val_loss: 11.5391 - val_acc: 0.2825\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/15\n",
      "509/509 [==============================] - 194s 382ms/step - loss: 10.7665 - acc: 0.3320 - val_loss: 11.5768 - val_acc: 0.2803\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/15\n",
      "509/509 [==============================] - 195s 383ms/step - loss: 11.2098 - acc: 0.3045 - val_loss: 11.7573 - val_acc: 0.2691\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/15\n",
      "509/509 [==============================] - 195s 383ms/step - loss: 11.0357 - acc: 0.3153 - val_loss: 11.6011 - val_acc: 0.2803\n",
      "\n",
      "Epoch 00011: val_acc did not improve\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create simple classifier and use after network\n",
    "\"\"\"\n",
    "\n",
    "main_input = Input(shape=(img_width, img_height, 3))\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=main_input)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "\"\"\"\n",
    "Load Simple MLP\n",
    "\"\"\"\n",
    "aux_input = Input(shape=(features,))\n",
    "aux = Dense(4096, activation='relu')(aux_input)\n",
    "aux = Dense(4096, activation='relu')(aux)\n",
    "\n",
    "# Merge input models\n",
    "merge = concatenate([x, aux])\n",
    "# interpretation\n",
    "predictions = Dense(4, activation='softmax')(merge)\n",
    "\n",
    "model = Model(inputs=[main_input, aux_input], outputs=predictions)\n",
    "top_weights_path = 'models/multi_vgg16_top_model.h5'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "opt = SGD(lr=0.00001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback_list = [\n",
    "    ModelCheckpoint(top_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "    EarlyStopping(monitor='val_acc', patience=5, verbose=0),\n",
    "    TensorBoard(log_dir=f'logs/multi_vgg16')\n",
    "]\n",
    "\n",
    "model.fit_generator(\n",
    "    csv_train_generator,\n",
    "    steps_per_epoch=1019 // batch_size,\n",
    "    epochs=15,\n",
    "    validation_data=csv_test_generator,\n",
    "    validation_steps=446 // batch_size,\n",
    "    callbacks=callback_list)\n",
    "\n",
    "model.load_weights(top_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "509/509 [==============================] - 162s 319ms/step - loss: 10.9723 - acc: 0.3193 - val_loss: 11.2495 - val_acc: 0.3004\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.29821 to 0.30045, saving model to models/multi_vgg16_top_model.h5\n",
      "Epoch 2/15\n",
      "509/509 [==============================] - 175s 343ms/step - loss: 10.9090 - acc: 0.3232 - val_loss: 11.4360 - val_acc: 0.2892\n",
      "\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 3/15\n",
      "509/509 [==============================] - 181s 357ms/step - loss: 11.2098 - acc: 0.3045 - val_loss: 11.5372 - val_acc: 0.2825\n",
      "\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 4/15\n",
      "509/509 [==============================] - 183s 359ms/step - loss: 10.8299 - acc: 0.3281 - val_loss: 11.4275 - val_acc: 0.2892\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/15\n",
      "509/509 [==============================] - 183s 359ms/step - loss: 11.1307 - acc: 0.3094 - val_loss: 11.6802 - val_acc: 0.2735\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/15\n",
      "509/509 [==============================] - 184s 361ms/step - loss: 11.0990 - acc: 0.3114 - val_loss: 11.6489 - val_acc: 0.2758\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "After training for a few epochs, freeze the bottom layers, and train only on top.\n",
    "\"\"\"\n",
    "for layer in model.layers[:vgg16_last_block_layer_number]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[vgg16_last_block_layer_number:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "opt = SGD(lr=0.00001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "final_weights_path = 'models/multi_vgg16_top_model.h5'\n",
    "\n",
    "model.fit_generator(\n",
    "    csv_train_generator,\n",
    "    steps_per_epoch=1019 // batch_size,\n",
    "    epochs=15,\n",
    "    validation_data=csv_test_generator,\n",
    "    validation_steps=446 // batch_size,\n",
    "    callbacks=callback_list)\n",
    "\n",
    "model.save(final_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(446,)\n",
      "(446,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "y_predict = model.predict_generator(csv_test_generator, steps=test_generator.n/2)\n",
    "y_predict_classes = y_predict.argmax(axis=-1)\n",
    "\n",
    "print(y_predict_classes.shape)\n",
    "print(test_generator.classes.shape)\n",
    "cm = confusion_matrix(test_generator.classes, y_predict_classes)\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.title('IMAGES + DATA')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
